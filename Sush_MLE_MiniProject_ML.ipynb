{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUlhqdY/mq/4rutYMKeDhM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sushkbura/MiniProject_ML_ModelEvaluation/blob/main/Sush_MLE_MiniProject_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FQdmxKaJcU8j"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/sushkbura/MiniProject_ML_ModelEvaluation/main/yellow_tripdata_2022-01.parquet\"\n",
        "df = pd.read_parquet(url, engine=\"pyarrow\")"
      ],
      "metadata": {
        "id": "aRuPmIjNhPPd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the dataset\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_rsX_2FhhUM",
        "outputId": "5d898b0a-d4fb-401f-d7ba-8621ff466bcf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
            "0         1  2022-01-01 00:35:40   2022-01-01 00:53:29              2.0   \n",
            "1         1  2022-01-01 00:33:43   2022-01-01 00:42:07              1.0   \n",
            "2         2  2022-01-01 00:53:21   2022-01-01 01:02:19              1.0   \n",
            "3         2  2022-01-01 00:25:21   2022-01-01 00:35:23              1.0   \n",
            "4         2  2022-01-01 00:36:48   2022-01-01 01:14:20              1.0   \n",
            "\n",
            "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
            "0           3.80         1.0                  N           142           236   \n",
            "1           2.10         1.0                  N           236            42   \n",
            "2           0.97         1.0                  N           166           166   \n",
            "3           1.09         1.0                  N           114            68   \n",
            "4           4.30         1.0                  N            68           163   \n",
            "\n",
            "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
            "0             1         14.5    3.0      0.5        3.65           0.0   \n",
            "1             1          8.0    0.5      0.5        4.00           0.0   \n",
            "2             1          7.5    0.5      0.5        1.76           0.0   \n",
            "3             2          8.0    0.5      0.5        0.00           0.0   \n",
            "4             1         23.5    0.5      0.5        3.00           0.0   \n",
            "\n",
            "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
            "0                    0.3         21.95                   2.5          0.0  \n",
            "1                    0.3         13.30                   0.0          0.0  \n",
            "2                    0.3         10.56                   0.0          0.0  \n",
            "3                    0.3         11.80                   2.5          0.0  \n",
            "4                    0.3         30.30                   2.5          0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing values.\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "BCfnUOfNhpgZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new feature, 'trip_duration'.\n",
        "df[\"trip_duration\"] = (\n",
        "    (df[\"tpep_dropoff_datetime\"] - df[\"tpep_pickup_datetime\"])\n",
        "    .dt.total_seconds() / 60.0\n",
        ")"
      ],
      "metadata": {
        "id": "Z-s73nAsh1yF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create target variable name\n",
        "target_variable = \"total_amount\""
      ],
      "metadata": {
        "id": "DPr1HhmZic1r"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list called feature_col to store column names\n",
        "feature_cols = [\n",
        "    \"VendorID\",\n",
        "    \"trip_distance\",\n",
        "    \"payment_type\",\n",
        "    \"PULocationID\",\n",
        "    \"DOLocationID\",\n",
        "    \"trip_duration\",\n",
        "]"
      ],
      "metadata": {
        "id": "DoClUzopid9u"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and test sets\n",
        "X = df[feature_cols]\n",
        "y = df[target_variable]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "JzXggNqGl0tR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a baseline for mean absolute error of total amount\n",
        "\n",
        "# Calculate the mean total fare from the training set\n",
        "baseline_pred = y_train.mean()\n",
        "\n",
        "# Predict this value for every example in the test set\n",
        "y_pred_baseline = np.full_like(y_test, fill_value=baseline_pred, dtype=float)\n",
        "\n",
        "# Evaluate using Mean Absolute Error\n",
        "baseline_mae = mean_absolute_error(y_test, y_pred_baseline)\n",
        "\n",
        "print(\"Baseline MAE (predicting the mean):\", baseline_mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlhJeIz0l2rU",
        "outputId": "388f95d9-d027-43a0-e8d8-679a61b09ce9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline MAE (predicting the mean): 9.198227928516678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Scikit-Learn's ColumnTransformer to preprocess the categorical and\n",
        "# continuous features independently.\n",
        "\n",
        "numeric_features = [\"trip_distance\", \"trip_duration\"]\n",
        "categorical_features = [\"VendorID\", \"payment_type\", \"PULocationID\", \"DOLocationID\"]\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), numeric_features),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "pQYNoUinCUqW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pipeline object containing the column transformations and regression\n",
        "# model.\n",
        "\n",
        "linreg_pipeline = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"model\", LinearRegression())\n",
        "])"
      ],
      "metadata": {
        "id": "bvcB3ultCpex"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the pipeline on the training data.\n",
        "\n",
        "linreg_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data.\n",
        "\n",
        "y_pred_linreg = linreg_pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the model using MAE and compare to baseline\n",
        "linreg_mae = mean_absolute_error(y_test, y_pred_linreg)\n",
        "print(\"Baseline MAE (predicting the mean):\", baseline_mae)\n",
        "print(\"Linear Regression MAE:\", linreg_mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvUGcpxwCtK1",
        "outputId": "d9fc6996-a8d7-43a0-fd4d-5613625e50e5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline MAE (predicting the mean): 9.198227928516678\n",
            "Linear Regression MAE: 3.3854544988959763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample_size = 50_000  # to speed up the process\n",
        "\n",
        "if len(X_train) > train_sample_size:\n",
        "    X_train_small = X_train.sample(train_sample_size, random_state=42)\n",
        "    y_train_small = y_train.loc[X_train_small.index]\n",
        "else:\n",
        "    X_train_small = X_train\n",
        "    y_train_small = y_train\n",
        "\n",
        "# Build random forest regressor model\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=100,   # fewer trees than 200 → faster\n",
        "    max_depth=20,      # shallower trees → faster\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf_pipeline = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"model\", rf_model)\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data.\n",
        "rf_pipeline.fit(X_train_small, y_train_small)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_rf = rf_pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate using MAE\n",
        "rf_mae = mean_absolute_error(y_test, y_pred_rf)\n",
        "print(\"Baseline MAE (predicting the mean):\", baseline_mae)\n",
        "print(\"Linear Regression MAE:\", linreg_mae)\n",
        "print(\"Random Forest MAE:\", rf_mae)"
      ],
      "metadata": {
        "id": "iRFvgZr-Jflc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc223315-a3e0-43f8-a7af-cc022123c599"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline MAE (predicting the mean): 9.198227928516678\n",
            "Linear Regression MAE: 3.3854544988959763\n",
            "Random Forest MAE: 1.6246708511752004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MwQ9v63m6vvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameters to tune.\n",
        "param_grid = {\n",
        "    \"model__n_estimators\": [50, 100],   # number of trees\n",
        "    \"model__max_depth\": [10, 20],       # tree depth\n",
        "    \"model__min_samples_split\": [2],    # min samples to split (kept fixed but included)\n",
        "}\n",
        "\n",
        "# Use a small sample for Grid Search so it completes on free Colab\n",
        "train_sample_size = 5_000\n",
        "if len(X_train) > train_sample_size:\n",
        "    X_train_gs = X_train.sample(train_sample_size, random_state=42)\n",
        "    y_train_gs = y_train.loc[X_train_gs.index]\n",
        "else:\n",
        "    X_train_gs = X_train\n",
        "    y_train_gs = y_train\n",
        "\n",
        "rf_base = RandomForestRegressor(\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf_pipeline = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"model\", rf_base)\n",
        "])\n",
        "\n",
        "# Perform grid search to find the best hyperparameters. This could take a while.\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf_pipeline,\n",
        "    param_grid=param_grid,\n",
        "    cv=3,\n",
        "    scoring=\"neg_mean_absolute_error\",\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train_gs, y_train_gs)\n",
        "\n",
        "# Get the best model and its parameters.\n",
        "print(\"Best parameters found:\", grid_search.best_params_)\n",
        "print(\"Best CV score (negative MAE):\", grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ojAfjxzkO_j",
        "outputId": "5918a56a-c97b-4d19-baec-1a0b4324b096"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "Best parameters found: {'model__max_depth': 20, 'model__min_samples_split': 2, 'model__n_estimators': 100}\n",
            "Best CV score (negative MAE): -1.7717111165844397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get the best model and its parameters.\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "best_n_estimators = best_params[\"model__n_estimators\"]\n",
        "best_max_depth = best_params[\"model__max_depth\"]\n",
        "best_min_samples_split = best_params[\"model__min_samples_split\"]\n",
        "\n",
        "# Sample training data for faster training in free Colab\n",
        "train_sample_size = 50_000\n",
        "if len(X_train) > train_sample_size:\n",
        "    X_train_final = X_train.sample(train_sample_size, random_state=42)\n",
        "    y_train_final = y_train.loc[X_train_final.index]\n",
        "else:\n",
        "    X_train_final = X_train\n",
        "    y_train_final = y_train\n",
        "\n",
        "# Fit the best classifier on the training data.\n",
        "rf_best = RandomForestRegressor(\n",
        "    n_estimators=best_n_estimators,\n",
        "    max_depth=best_max_depth,\n",
        "    min_samples_split=best_min_samples_split,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf_best_pipeline = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"model\", rf_best)\n",
        "])\n",
        "\n",
        "rf_best_pipeline.fit(X_train_final, y_train_final)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_best = rf_best_pipeline.predict(X_test)\n",
        "\n",
        "tuned_rf_mae = mean_absolute_error(y_test, y_pred_best)\n",
        "\n",
        "print(\"Baseline MAE (predicting the mean):\", baseline_mae)\n",
        "print(\"Linear Regression MAE:\", linreg_mae)\n",
        "print(\"Tuned Random Forest MAE:\", tuned_rf_mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO6GC2nXuWHi",
        "outputId": "49fe0304-704b-41ef-c7c1-10f205731852"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline MAE (predicting the mean): 9.198227928516678\n",
            "Linear Regression MAE: 3.3854544988959763\n",
            "Tuned Random Forest MAE: 1.6246708511752004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The baseline model had an error of about $9.20.\n",
        "#Linear Regression improved this to about $3.39.\n",
        "#After tuning a Random Forest model, the error dropped to about $1.62.\n",
        "#This means the Random Forest did the best job because it can learn more complex patterns in the data."
      ],
      "metadata": {
        "id": "Q8n_elAcwdGF"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}